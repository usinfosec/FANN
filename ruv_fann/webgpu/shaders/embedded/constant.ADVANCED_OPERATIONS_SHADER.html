<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Advanced neural network operations shader"><title>ADVANCED_OPERATIONS_SHADER in ruv_fann::webgpu::shaders::embedded - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Italic-81dc35de.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-MediumItalic-ccf7e434.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../../../../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../../../../static.files/rustdoc-1a91846b.css"><meta name="rustdoc-vars" data-root-path="../../../../" data-static-root-path="../../../../static.files/" data-current-crate="ruv_fann" data-themes="" data-resource-suffix="" data-rustdoc-version="1.88.0 (6b00bc388 2025-06-23)" data-channel="1.88.0" data-search-js="search-f7877310.js" data-settings-js="settings-5514c975.js" ><script src="../../../../static.files/storage-4e99c027.js"></script><script defer src="sidebar-items.js"></script><script defer src="../../../../static.files/main-7ef8a74a.js"></script><noscript><link rel="stylesheet" href="../../../../static.files/noscript-893ab5e7.css"></noscript><link rel="alternate icon" type="image/png" href="../../../../static.files/favicon-32x32-6580c154.png"><link rel="icon" type="image/svg+xml" href="../../../../static.files/favicon-044be391.svg"></head><body class="rustdoc constant"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle" title="show sidebar"></button></nav><nav class="sidebar"><div class="sidebar-crate"><h2><a href="../../../../ruv_fann/index.html">ruv_<wbr>fann</a><span class="version">0.1.6</span></h2></div><div class="sidebar-elems"><div id="rustdoc-modnav"><h2><a href="index.html">In ruv_<wbr>fann::<wbr>webgpu::<wbr>shaders::<wbr>embedded</a></h2></div></div></nav><div class="sidebar-resizer"></div><main><div class="width-limiter"><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><div class="rustdoc-breadcrumbs"><a href="../../../index.html">ruv_fann</a>::<wbr><a href="../../index.html">webgpu</a>::<wbr><a href="../index.html">shaders</a>::<wbr><a href="index.html">embedded</a></div><h1>Constant <span class="constant">ADVANCED_OPERATIONS_SHADER</span><button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><rustdoc-toolbar></rustdoc-toolbar><span class="sub-heading"><a class="src" href="../../../../src/ruv_fann/webgpu/shaders.rs.html#20">Source</a> </span></div><pre class="rust item-decl"><code>pub const ADVANCED_OPERATIONS_SHADER: &amp;<a class="primitive" href="https://doc.rust-lang.org/1.88.0/std/primitive.str.html">str</a> = &quot;// WebGPU Compute Shaders: Advanced Neural Network Operations\n// High-performance GPU implementations of specialized neural operations\n// Includes convolution, pooling, attention, and optimization kernels\n\n@group(0) @binding(0) var&lt;storage, read&gt; input_data: array&lt;f32&gt;;\n@group(0) @binding(1) var&lt;storage, read&gt; weights: array&lt;f32&gt;;\n@group(0) @binding(2) var&lt;storage, read&gt; bias: array&lt;f32&gt;;\n@group(0) @binding(3) var&lt;storage, read_write&gt; output_data: array&lt;f32&gt;;\n@group(0) @binding(4) var&lt;storage, read_write&gt; scratch_buffer: array&lt;f32&gt;;\n\nstruct AdvancedUniforms {\n    input_height: u32,\n    input_width: u32,\n    input_channels: u32,\n    output_channels: u32,\n    kernel_size: u32,\n    stride: u32,\n    padding: u32,\n    batch_size: u32,\n    sequence_length: u32,    // For attention mechanisms\n    head_dimension: u32,     // For multi-head attention\n    num_heads: u32,\n    scale_factor: f32,       // For attention scaling\n}\n\n@group(0) @binding(5) var&lt;uniform&gt; uniforms: AdvancedUniforms;\n\n// 2D Convolution operation optimized for GPU\n@compute @workgroup_size(16, 16, 1)\nfn conv2d_main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {\n    let batch_idx = global_id.x;\n    let out_y = global_id.y;\n    let out_x = global_id.z;\n    \n    if (batch_idx &gt;= uniforms.batch_size || \n        out_y &gt;= uniforms.input_height || \n        out_x &gt;= uniforms.input_width) {\n        return;\n    }\n    \n    let output_height = (uniforms.input_height + 2u * uniforms.padding - uniforms.kernel_size) / uniforms.stride + 1u;\n    let output_width = (uniforms.input_width + 2u * uniforms.padding - uniforms.kernel_size) / uniforms.stride + 1u;\n    \n    if (out_y &gt;= output_height || out_x &gt;= output_width) {\n        return;\n    }\n    \n    // Compute convolution for each output channel\n    for (var out_c = 0u; out_c &lt; uniforms.output_channels; out_c++) {\n        var sum: f32 = 0.0;\n        \n        // Convolve with kernel\n        for (var ky = 0u; ky &lt; uniforms.kernel_size; ky++) {\n            for (var kx = 0u; kx &lt; uniforms.kernel_size; kx++) {\n                for (var in_c = 0u; in_c &lt; uniforms.input_channels; in_c++) {\n                    let in_y = out_y * uniforms.stride + ky - uniforms.padding;\n                    let in_x = out_x * uniforms.stride + kx - uniforms.padding;\n                    \n                    // Check bounds (padding)\n                    if (in_y &lt; uniforms.input_height &amp;&amp; in_x &lt; uniforms.input_width) {\n                        let input_idx = batch_idx * (uniforms.input_channels * uniforms.input_height * uniforms.input_width) +\n                                      in_c * (uniforms.input_height * uniforms.input_width) +\n                                      in_y * uniforms.input_width + in_x;\n                        \n                        let weight_idx = out_c * (uniforms.input_channels * uniforms.kernel_size * uniforms.kernel_size) +\n                                       in_c * (uniforms.kernel_size * uniforms.kernel_size) +\n                                       ky * uniforms.kernel_size + kx;\n                        \n                        sum += input_data[input_idx] * weights[weight_idx];\n                    }\n                }\n            }\n        }\n        \n        // Add bias and store result\n        let output_idx = batch_idx * (uniforms.output_channels * output_height * output_width) +\n                        out_c * (output_height * output_width) +\n                        out_y * output_width + out_x;\n        \n        output_data[output_idx] = sum + bias[out_c];\n    }\n}\n\n// Max pooling operation\n@compute @workgroup_size(16, 16, 1)\nfn max_pool2d_main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {\n    let batch_idx = global_id.x;\n    let out_y = global_id.y;\n    let out_x = global_id.z;\n    \n    let pool_size = uniforms.kernel_size;\n    let output_height = uniforms.input_height / pool_size;\n    let output_width = uniforms.input_width / pool_size;\n    \n    if (batch_idx &gt;= uniforms.batch_size || \n        out_y &gt;= output_height || \n        out_x &gt;= output_width) {\n        return;\n    }\n    \n    for (var c = 0u; c &lt; uniforms.input_channels; c++) {\n        var max_val: f32 = -3.4e38; // Negative infinity approximation\n        \n        // Find maximum in pool window\n        for (var py = 0u; py &lt; pool_size; py++) {\n            for (var px = 0u; px &lt; pool_size; px++) {\n                let in_y = out_y * pool_size + py;\n                let in_x = out_x * pool_size + px;\n                \n                let input_idx = batch_idx * (uniforms.input_channels * uniforms.input_height * uniforms.input_width) +\n                              c * (uniforms.input_height * uniforms.input_width) +\n                              in_y * uniforms.input_width + in_x;\n                \n                max_val = max(max_val, input_data[input_idx]);\n            }\n        }\n        \n        let output_idx = batch_idx * (uniforms.input_channels * output_height * output_width) +\n                        c * (output_height * output_width) +\n                        out_y * output_width + out_x;\n        \n        output_data[output_idx] = max_val;\n    }\n}\n\n// Average pooling operation\n@compute @workgroup_size(16, 16, 1)\nfn avg_pool2d_main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {\n    let batch_idx = global_id.x;\n    let out_y = global_id.y;\n    let out_x = global_id.z;\n    \n    let pool_size = uniforms.kernel_size;\n    let output_height = uniforms.input_height / pool_size;\n    let output_width = uniforms.input_width / pool_size;\n    \n    if (batch_idx &gt;= uniforms.batch_size || \n        out_y &gt;= output_height || \n        out_x &gt;= output_width) {\n        return;\n    }\n    \n    for (var c = 0u; c &lt; uniforms.input_channels; c++) {\n        var sum: f32 = 0.0;\n        \n        // Sum values in pool window\n        for (var py = 0u; py &lt; pool_size; py++) {\n            for (var px = 0u; px &lt; pool_size; px++) {\n                let in_y = out_y * pool_size + py;\n                let in_x = out_x * pool_size + px;\n                \n                let input_idx = batch_idx * (uniforms.input_channels * uniforms.input_height * uniforms.input_width) +\n                              c * (uniforms.input_height * uniforms.input_width) +\n                              in_y * uniforms.input_width + in_x;\n                \n                sum += input_data[input_idx];\n            }\n        }\n        \n        // Average and store\n        let avg_val = sum / f32(pool_size * pool_size);\n        let output_idx = batch_idx * (uniforms.input_channels * output_height * output_width) +\n                        c * (output_height * output_width) +\n                        out_y * output_width + out_x;\n        \n        output_data[output_idx] = avg_val;\n    }\n}\n\n// Softmax operation with numerical stability\n@compute @workgroup_size(256)\nfn softmax_main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {\n    let batch_idx = global_id.x;\n    \n    if (batch_idx &gt;= uniforms.batch_size) {\n        return;\n    }\n    \n    let vector_size = uniforms.input_channels;\n    let base_idx = batch_idx * vector_size;\n    \n    // Find maximum for numerical stability\n    var max_val: f32 = -3.4e38;\n    for (var i = 0u; i &lt; vector_size; i++) {\n        max_val = max(max_val, input_data[base_idx + i]);\n    }\n    \n    // Compute sum of exponentials\n    var exp_sum: f32 = 0.0;\n    for (var i = 0u; i &lt; vector_size; i++) {\n        let exp_val = exp(input_data[base_idx + i] - max_val);\n        scratch_buffer[base_idx + i] = exp_val;\n        exp_sum += exp_val;\n    }\n    \n    // Normalize\n    for (var i = 0u; i &lt; vector_size; i++) {\n        output_data[base_idx + i] = scratch_buffer[base_idx + i] / exp_sum;\n    }\n}\n\n// Layer normalization\n@compute @workgroup_size(256)\nfn layer_norm_main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {\n    let batch_idx = global_id.x;\n    \n    if (batch_idx &gt;= uniforms.batch_size) {\n        return;\n    }\n    \n    let feature_size = uniforms.input_channels;\n    let base_idx = batch_idx * feature_size;\n    let epsilon = 1e-5;\n    \n    // Compute mean\n    var mean: f32 = 0.0;\n    for (var i = 0u; i &lt; feature_size; i++) {\n        mean += input_data[base_idx + i];\n    }\n    mean /= f32(feature_size);\n    \n    // Compute variance\n    var variance: f32 = 0.0;\n    for (var i = 0u; i &lt; feature_size; i++) {\n        let diff = input_data[base_idx + i] - mean;\n        variance += diff * diff;\n    }\n    variance /= f32(feature_size);\n    \n    // Normalize\n    let inv_std = 1.0 / sqrt(variance + epsilon);\n    for (var i = 0u; i &lt; feature_size; i++) {\n        let normalized = (input_data[base_idx + i] - mean) * inv_std;\n        \n        // Apply learned scale and bias if available\n        let scale = select(1.0, weights[i], i &lt; uniforms.input_channels);\n        let bias_val = select(0.0, bias[i], i &lt; uniforms.input_channels);\n        \n        output_data[base_idx + i] = normalized * scale + bias_val;\n    }\n}\n\n// Scaled dot-product attention (simplified)\n@compute @workgroup_size(16, 16)\nfn scaled_dot_product_attention(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {\n    let batch_idx = global_id.x;\n    let head_idx = global_id.y;\n    let seq_pos = global_id.z;\n    \n    if (batch_idx &gt;= uniforms.batch_size || \n        head_idx &gt;= uniforms.num_heads || \n        seq_pos &gt;= uniforms.sequence_length) {\n        return;\n    }\n    \n    let head_dim = uniforms.head_dimension;\n    let scale = uniforms.scale_factor;\n    \n    // This is a simplified version - full attention would require Q, K, V matrices\n    let base_offset = batch_idx * uniforms.num_heads * uniforms.sequence_length * head_dim +\n                     head_idx * uniforms.sequence_length * head_dim +\n                     seq_pos * head_dim;\n    \n    // Compute attention scores (simplified)\n    var attention_sum: f32 = 0.0;\n    for (var i = 0u; i &lt; uniforms.sequence_length; i++) {\n        let query_offset = base_offset;\n        let key_offset = batch_idx * uniforms.num_heads * uniforms.sequence_length * head_dim +\n                        head_idx * uniforms.sequence_length * head_dim +\n                        i * head_dim;\n        \n        // Compute dot product\n        var dot_product: f32 = 0.0;\n        for (var d = 0u; d &lt; head_dim; d++) {\n            dot_product += input_data[query_offset + d] * weights[key_offset + d];\n        }\n        \n        let attention_score = exp(dot_product * scale);\n        scratch_buffer[seq_pos * uniforms.sequence_length + i] = attention_score;\n        attention_sum += attention_score;\n    }\n    \n    // Normalize attention weights and compute output\n    for (var d = 0u; d &lt; head_dim; d++) {\n        var weighted_sum: f32 = 0.0;\n        \n        for (var i = 0u; i &lt; uniforms.sequence_length; i++) {\n            let attention_weight = scratch_buffer[seq_pos * uniforms.sequence_length + i] / attention_sum;\n            let value_offset = batch_idx * uniforms.num_heads * uniforms.sequence_length * head_dim +\n                              head_idx * uniforms.sequence_length * head_dim +\n                              i * head_dim + d;\n            \n            weighted_sum += attention_weight * bias[value_offset]; // Reuse bias buffer for values\n        }\n        \n        output_data[base_offset + d] = weighted_sum;\n    }\n}\n\n// Element-wise operations\n@compute @workgroup_size(256)\nfn element_wise_add(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {\n    let index = global_id.x;\n    \n    if (index &gt;= uniforms.batch_size * uniforms.input_channels) {\n        return;\n    }\n    \n    output_data[index] = input_data[index] + weights[index];\n}\n\n@compute @workgroup_size(256)\nfn element_wise_multiply(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {\n    let index = global_id.x;\n    \n    if (index &gt;= uniforms.batch_size * uniforms.input_channels) {\n        return;\n    }\n    \n    output_data[index] = input_data[index] * weights[index];\n}\n\n// GELU activation: f(x) = x * Phi(x) where Phi is cumulative distribution function\n@compute @workgroup_size(256)\nfn gelu_main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {\n    let index = global_id.x;\n    \n    if (index &gt;= uniforms.batch_size * uniforms.input_channels) {\n        return;\n    }\n    \n    let x = input_data[index];\n    \n    // GELU approximation: 0.5 * x * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3)))\n    let sqrt_2_over_pi = 0.7978845608;\n    let a = 0.044715;\n    \n    let x_cubed = x * x * x;\n    let inner = sqrt_2_over_pi * (x + a * x_cubed);\n    let gelu_approx = 0.5 * x * (1.0 + tanh(inner));\n    \n    output_data[index] = gelu_approx;\n}\n\n// Swish/SiLU activation: f(x) = x * sigmoid(x)\n@compute @workgroup_size(256)\nfn swish_main(@builtin(global_invocation_id) global_id: vec3&lt;u32&gt;) {\n    let index = global_id.x;\n    \n    if (index &gt;= uniforms.batch_size * uniforms.input_channels) {\n        return;\n    }\n    \n    let x = input_data[index];\n    let sigmoid_x = 1.0 / (1.0 + exp(-x));\n    \n    output_data[index] = x * sigmoid_x;\n}&quot;;</code></pre><details class="toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><p>Advanced neural network operations shader</p>
</div></details></section></div></main></body></html>