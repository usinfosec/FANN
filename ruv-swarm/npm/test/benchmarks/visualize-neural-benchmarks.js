#!/usr/bin/env node
/**
 * Neural Benchmark Visualization
 * Creates visual representations of benchmark results
 */

import { promises as fs } from 'fs';
import path from 'path';

class BenchmarkVisualizer {
  constructor() {
    this.benchmarkData = null;
  }

  async loadBenchmarkData() {
    const benchmarkPath = path.join(process.cwd(), '.ruv-swarm', 'benchmarks', 'neural-benchmark-1751398753060.json');
    this.benchmarkData = JSON.parse(await fs.readFile(benchmarkPath, 'utf8'));
  }

  generateASCIIChart(data, title, maxWidth = 60) {
    console.log(`\n${title}`);
    console.log('=' .repeat(maxWidth));

    const maxValue = Math.max(...Object.values(data));

    Object.entries(data).forEach(([label, value]) => {
      const barLength = Math.floor((value / maxValue) * (maxWidth - 20));
      const bar = '‚ñà'.repeat(barLength);
      const percentage = ((value / maxValue) * 100).toFixed(1);
      console.log(`${label.padEnd(12)} ${bar} ${value} (${percentage}%)`);
    });
  }

  visualizeResults() {
    console.log('\nüß† NEURAL MODEL BENCHMARK VISUALIZATION');
    console.log('=' .repeat(70));
    console.log(`üìÖ Benchmark Date: ${this.benchmarkData.timestamp}`);
    console.log(`‚è±Ô∏è  Total Duration: ${(this.benchmarkData.duration / 1000).toFixed(2)} seconds`);

    // Accuracy Comparison
    const accuracyData = {};
    Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
      accuracyData[model.toUpperCase()] = parseFloat(data.architecture.accuracy);
    });
    this.generateASCIIChart(accuracyData, 'üéØ MODEL ACCURACY COMPARISON (%)', 70);

    // Inference Speed Comparison
    const speedData = {};
    Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
      speedData[model.toUpperCase()] = Math.floor(data.inference.mean);
    });
    this.generateASCIIChart(speedData, '‚ö° INFERENCE SPEED (ops/sec)', 70);

    // Memory Usage Comparison
    const memoryData = {};
    Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
      memoryData[model.toUpperCase()] = data.memory.totalMemory;
    });
    this.generateASCIIChart(memoryData, 'üíæ MEMORY USAGE (MB)', 70);

    // Training Time Comparison
    const trainingData = {};
    Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
      trainingData[model.toUpperCase()] = Math.floor(data.timings.training);
    });
    this.generateASCIIChart(trainingData, '‚è±Ô∏è  TRAINING TIME (ms)', 70);

    // Parameter Count Comparison
    const paramData = {};
    Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
      paramData[model.toUpperCase()] = Math.floor(data.architecture.parameters / 1000);
    });
    this.generateASCIIChart(paramData, 'üî¢ PARAMETERS (thousands)', 70);

    // Performance Matrix
    this.generatePerformanceMatrix();

    // Model Rankings
    this.generateModelRankings();

    // Trade-off Analysis
    this.generateTradeoffAnalysis();
  }

  generatePerformanceMatrix() {
    console.log('\nüìä PERFORMANCE MATRIX');
    console.log('=' .repeat(70));
    console.log('Model        | Accuracy | Speed    | Memory  | Training | Parameters');
    console.log('-------------|----------|----------|---------|----------|------------');

    Object.entries(this.benchmarkData.results).forEach(([model, data]) => {
      const row = [
        model.toUpperCase().padEnd(12),
        `${data.architecture.accuracy}%`.padEnd(9),
        `${Math.floor(data.inference.mean)} ops/s`.padEnd(9),
        `${data.memory.totalMemory} MB`.padEnd(8),
        `${(data.timings.training / 1000).toFixed(2)}s`.padEnd(9),
        `${(data.architecture.parameters / 1000).toFixed(0)}K`,
      ];
      console.log(row.join(' | '));
    });
  }

  generateModelRankings() {
    console.log('\nüèÜ MODEL RANKINGS BY METRIC');
    console.log('=' .repeat(70));

    // Rank by different metrics
    const metrics = [
      { name: 'Accuracy', key: 'architecture.accuracy', higher: true, unit: '%' },
      { name: 'Inference Speed', key: 'inference.mean', higher: true, unit: ' ops/s' },
      { name: 'Memory Efficiency', key: 'memory.efficiency', higher: true, unit: '%' },
      { name: 'Training Speed', key: 'timings.training', higher: false, unit: 'ms' },
      { name: 'Parameter Efficiency', key: 'architecture.parameters', higher: false, unit: '' },
    ];

    metrics.forEach(metric => {
      console.log(`\n${metric.name}:`);
      const ranked = Object.entries(this.benchmarkData.results)
        .map(([model, data]) => {
          const value = metric.key.split('.').reduce((obj, key) => obj[key], data);
          return { model, value };
        })
        .sort((a, b) => metric.higher ? b.value - a.value : a.value - b.value);

      ranked.forEach((item, index) => {
        const medal = index === 0 ? 'ü•á' : index === 1 ? 'ü•à' : index === 2 ? 'ü•â' : '  ';
        const value = metric.unit === '%' ? parseFloat(item.value).toFixed(1) :
          Math.floor(item.value);
        console.log(`  ${medal} ${(index + 1)}. ${item.model.toUpperCase()}: ${value}${metric.unit}`);
      });
    });
  }

  generateTradeoffAnalysis() {
    console.log('\n‚öñÔ∏è  TRADE-OFF ANALYSIS');
    console.log('=' .repeat(70));

    const models = Object.entries(this.benchmarkData.results).map(([name, data]) => ({
      name: name.toUpperCase(),
      accuracy: parseFloat(data.architecture.accuracy),
      speed: data.inference.mean,
      memory: data.memory.totalMemory,
      efficiency: data.memory.efficiency,
    }));

    console.log('\nüìà Accuracy vs Speed Trade-off:');
    models.sort((a, b) => (b.accuracy * b.speed) - (a.accuracy * a.speed))
      .forEach(model => {
        const score = (model.accuracy * model.speed / 100).toFixed(1);
        console.log(`  ${model.name}: ${score} (${model.accuracy}% √ó ${Math.floor(model.speed)} ops/s)`);
      });

    console.log('\nüíæ Memory vs Performance Trade-off:');
    models.sort((a, b) => (b.accuracy / b.memory) - (a.accuracy / a.memory))
      .forEach(model => {
        const score = (model.accuracy / model.memory * 1000).toFixed(2);
        console.log(`  ${model.name}: ${score} (${model.accuracy}% / ${model.memory}MB)`);
      });

    console.log('\n‚ö° Overall Efficiency Score:');
    models.forEach(model => {
      // Normalize values (0-1 scale)
      const normAccuracy = model.accuracy / 100;
      const normSpeed = model.speed / 350; // Max speed ~350
      const normMemEff = 1 - (model.memory / 6000); // Inverse, lower is better
      const overallScore = ((normAccuracy * 0.4) + (normSpeed * 0.3) + (normMemEff * 0.3)) * 100;

      model.overallScore = overallScore;
    });

    models.sort((a, b) => b.overallScore - a.overallScore)
      .forEach((model, index) => {
        const medal = index === 0 ? 'üèÜ' : '';
        console.log(`  ${medal} ${model.name}: ${model.overallScore.toFixed(1)}/100`);
      });
  }

  async visualize() {
    try {
      await this.loadBenchmarkData();
      this.visualizeResults();

      console.log('\n\nüí° KEY INSIGHTS:');
      console.log('=' .repeat(70));
      console.log('‚Ä¢ Attention model achieves best accuracy (94.31%) with good memory efficiency');
      console.log('‚Ä¢ Feedforward offers 3x faster inference than any other model');
      console.log('‚Ä¢ Transformer provides best balance for parallel workloads');
      console.log('‚Ä¢ LSTM remains optimal for sequential data despite lower overall scores');
      console.log('\n‚úÖ Visualization complete!');
    } catch (error) {
      console.error('‚ùå Error:', error.message);
    }
  }
}

// Run visualization
const visualizer = new BenchmarkVisualizer();
visualizer.visualize();